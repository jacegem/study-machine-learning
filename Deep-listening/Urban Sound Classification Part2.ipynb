{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Sound Classification, Part 2\n",
    "\n",
    "출처: http://aqibsaeed.github.io/2016-09-24-urban-sound-classification-part-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part one, we learnt to extract various features from audio clips. We, also, trained a two layer neural network to classify each sound into a predefined category.\n",
    "\n",
    "Today, we will go one step further and see how we can apply COnvolution Neural Network(CNN) to perform the same task of urban sound classification\n",
    "\n",
    "> Note: If you want to get in-depth understanding of how CNN works. Kindly consult following resources:\n",
    "- http://cs231n.github.io/convolutional-networks/\n",
    "- https://arxiv.org/pdf/1603.07285v1.pdf\n",
    "- http://www.deeplearningbook.org/contents/convnets.html\n",
    "\n",
    "The well-known applicatoin of CNN is image classification, where a fixed dimension image is fed into a network along with different channels (RGB in the case of a color image) and after various steps of convolution, pooling and fully connected layers, network outputs class prpobabilities for the image.\n",
    "\n",
    "We want to do the smae, but here instead of an image, we have sound clips. A quick search on Google Scholar provide a lot of research papaers, which discuss the implementation of CNN on a sound dataset.\n",
    "\n",
    "A paper I foudn particularly interesting and quite relevant is `Environmental sound classification with convolutional neural networks by Karol J. Piczak.` I borrowed the idea of dataset (feature extraction) preparation for CNN from this papaer. For example: how to get equal size segments from varying length audio clips and which audio feature(s) we can feed as s separate channel (just like RGB of a color image) into the network. \n",
    "\n",
    "Once we have the initial dataset ready for the CNN. We can train as deep network (composed of different layers) as we want!\n",
    "\n",
    "Let's define a function to calcuate log scaled mel-spectrograms and their corresponding deltas from a sound clip. Regarding fixed size input, we will divide each sound clip into segments of 60x41 (60 rows and 41 columns).\n",
    "\n",
    "The mel-spec and their deltas will become two channels, which we will be fed into CNN. Other features can be calculated in the same way, which can be used as a separate input channel\n",
    "\n",
    "![](http://aqibsaeed.github.io/img/urban-sound-cnn.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    labels = []\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            sound_clip,s = librosa.load(fn)\n",
    "            label = fn.split('/')[2].split('-')[1]\n",
    "            for (start,end) in windows(sound_clip,window_size):\n",
    "                if(len(sound_clip[start:end]) == window_size):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                    logspec = librosa.logamplitude(melspec)\n",
    "                    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                    log_specgrams.append(logspec)\n",
    "                    labels.append(label)\n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features), np.array(labels,dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`extract-feature` and `windows` are the two methods we need to prepare the data (both features and labels) for CNN. `extract_features` iterates over all the fiels within subdirectories of a particular parent directory, calculate above-mentioned features along with class labels and append them to arrays.\n",
    "\n",
    "Let's call this method to extract features and labels and save them in corresponding variables. Also, convert labels into on hot vector using `one_hot_encode` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = 'Sound-Data'\n",
    "tr_sub_dirs= ['fold1','fold2']\n",
    "tr_features,tr_labels = extract_features(parent_dir,tr_sub_dirs)\n",
    "tr_labels = one_hot_encode(tr_labels)\n",
    "\n",
    "ts_sub_dirs= ['fold3']\n",
    "ts_features,ts_labels = extract_features(parent_dir,ts_sub_dirs)\n",
    "ts_labels = one_hot_encode(ts_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some helper functions for the implementation of CNN. The method named `weight_variable` and `bias_variable` will return Tensorflow variable of defined shapes, where bias variable is initialized with all ones and weight variable with zero mean and standard deviation of 0.1. \n",
    "\n",
    "The `Conv2d` method is just a wrapper over Tensorflow conv2d function. It will be called by `apply_convolution` function, which takes input data, kernel/filter size, a number of channels in the input and output depth or number of channelds in the output.\n",
    "\n",
    "It then gets weight and bias variables, applies convolution, adds the bias to the results and finally applies non-linearity(RELU).\n",
    "\n",
    "Max-Pooling can be applied using `apply_max_pool` function. It takes input data (usually output of convolution layer), kernel and stride size. I used the SAME padding, you can change it to VALID padding if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(1.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def apply_convolution(x,kernel_size,num_channels,depth):\n",
    "    weights = weight_variable([kernel_size, kernel_size, num_channels, depth])\n",
    "    biases = bias_variable([depth])\n",
    "    return tf.nn.relu(tf.add(conv2d(x, weights),biases))\n",
    "\n",
    "def apply_max_pool(x,kernel_size,stride_size):\n",
    "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1], \n",
    "                          strides=[1, stride_size, stride_size, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code provied below defines configuration parameters required by CNN model. Such as kernel size, total iterations, a number of neurons in each hidden layer and learning rate etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = 41\n",
    "bands = 60\n",
    "\n",
    "feature_size = 2460 #60x41\n",
    "num_labels = 10\n",
    "num_channels = 2\n",
    "\n",
    "batch_size = 50\n",
    "kernel_size = 30\n",
    "depth = 20\n",
    "num_hidden = 200\n",
    "\n",
    "learning_rate = 0.01\n",
    "total_iterations = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow placehodler for input and output data are defined next. A convolution funcion is applied with a filter size of 30 and depth of 20 (number of channels, we will get as output from convolution layer).\n",
    "\n",
    "Next, the convolution output is flattened out for the fully connected layer input. There are 200 neurones in the fully connnected layer as definded by the above configuration. \n",
    "\n",
    "The Sigmoid function is used as non-linearity in this layer. Lastly, the Softmax layer is defined to output probabilites of the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,bands,frames,num_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,num_labels])\n",
    "\n",
    "cov = apply_convolution(X,kernel_size,num_channels,depth)\n",
    "\n",
    "shape = cov.get_shape().as_list()\n",
    "cov_flat = tf.reshape(cov, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "f_weights = weight_variable([shape[1] * shape[2] * depth, num_hidden])\n",
    "f_biases = bias_variable([num_hidden])\n",
    "f = tf.nn.sigmoid(tf.add(tf.matmul(cov_flat, f_weights),f_biases))\n",
    "\n",
    "out_weights = weight_variable([num_hidden, num_labels])\n",
    "out_biases = bias_variable([num_labels])\n",
    "y_ = tf.nn.softmax(tf.matmul(f, out_weights) + out_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative log-likelihood cost function will be minimised using Adam optimizer, the code provided below initialize cost function and optimizer. Also, define the code for accuracy calcuation of the prediction by model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -tf.reduce_sum(Y * tf.log(y_))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the following code will train the CNN model using a batch size of 50 for 2000 iterations. After the training, it clasifies testing set and prints out the achieved accuracy of the model along with plottingn cost as a function of a number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0, 0) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9ecde7252724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mcost_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    973\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    976\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0, 0) for Tensor 'Placeholder_1:0', which has shape '(?, 10)'"
     ]
    }
   ],
   "source": [
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "with tf.Session() as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for itr in range(total_iterations):    \n",
    "        offset = (itr * batch_size) % (tr_labels.shape[0] - batch_size)\n",
    "        batch_x = tr_features[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = tr_labels[offset:(offset + batch_size), :]\n",
    "        \n",
    "        _, c = session.run([optimizer, loss],feed_dict={X: batch_x, Y : batch_y})\n",
    "        cost_history = np.append(cost_history,c)\n",
    "    \n",
    "    print('Test accuracy: ',round(session.run(accuracy, feed_dict={X: ts_features, Y: ts_labels}) , 3))\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    plt.plot(cost_history)\n",
    "    plt.axis([0,total_iterations,0,np.max(cost_history)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This blog post discussed how to prepare a dataset for CNN and train a model with one convolution layer. I would encourage you to train deep models with several convolution, pooling and two or more fully connected layers on complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
