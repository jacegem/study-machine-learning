{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6: Q-Network\n",
    "\n",
    "## 링크\n",
    "- https://www.youtube.com/watch?v=w9GwqPx7LW8\n",
    "- http://computingkoreanlab.com/app/jAI/jQLearning/\n",
    "- https://github.com/awjuliani/DeepRL-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network tranining (linear regression)\n",
    "$$\n",
    "H(S) = Wx\n",
    "\\\\\n",
    "cost(W) = \\frac{1}{m}\\sum^{m}_{i=1}(Wx^{(i)}-y^{(i)})^{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "cost(W) = (Ws - y)^2\n",
    "\\\\\n",
    "y = r + \\gamma maxQ(s')\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network trainning (math notations)\n",
    "- Approximate $Q^*$ function using $\\theta$\n",
    "$$\n",
    "\\hat{Q}(s,a\\mid\\theta) \\sim Q^{*}(s,a)\n",
    "$$\n",
    "- Choose $\\theta$ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y label and loss function\n",
    "\n",
    "## Deterministic or Stochastic?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6-1: Q Network for Frozen Lake\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6-2: Q Network for Cart Pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "[-0.02926294  0.24063691  0.02840675 -0.32470439] 1.0 False\n",
      "[-0.0244502   0.04512224  0.02191266 -0.02320025] 1.0 False\n",
      "[-0.02354775 -0.15030699  0.02144865  0.27631503] 1.0 False\n",
      "[-0.02655389 -0.34572828  0.02697495  0.57568496] 1.0 False\n",
      "[-0.03346846 -0.54121778  0.03848865  0.8767422 ] 1.0 False\n",
      "[-0.04429282 -0.34663949  0.0560235   0.59640379] 1.0 False\n",
      "[-0.0512256  -0.15234446  0.06795157  0.32188079] 1.0 False\n",
      "[-0.05427249 -0.34836495  0.07438919  0.63519534] 1.0 False\n",
      "[-0.06123979 -0.54444132  0.08709309  0.95034675] 1.0 False\n",
      "[-0.07212862 -0.35059278  0.10610003  0.68624904] 1.0 False\n",
      "[-0.07914047 -0.54701512  0.11982501  1.01036065] 1.0 False\n",
      "[-0.09008078 -0.35367833  0.14003222  0.75757923] 1.0 False\n",
      "[-0.09715434 -0.16073537  0.15518381  0.51203279] 1.0 False\n",
      "[-0.10036905 -0.35766356  0.16542446  0.84931653] 1.0 False\n",
      "[-0.10752232 -0.55460825  0.18241079  1.18911396] 1.0 False\n",
      "[-0.11861449 -0.36225758  0.20619307  0.95870669] 1.0 False\n",
      "[-0.12585964 -0.17041444  0.22536721  0.73722971] 1.0 True\n",
      "Reward for this episode was: 17.0\n",
      "[-0.03074364 -0.17161721  0.00074017  0.25933737] 1.0 False\n",
      "[-0.03417598  0.02349417  0.00592692 -0.03311201] 1.0 False\n",
      "[-0.0337061  -0.17171227  0.00526468  0.26143502] 1.0 False\n",
      "[-0.03714034 -0.36690898  0.01049338  0.55577383] 1.0 False\n",
      "[-0.04447852 -0.17193592  0.02160886  0.26641533] 1.0 False\n",
      "[-0.04791724  0.02287107  0.02693716 -0.01937442] 1.0 False\n",
      "[-0.04745982 -0.17262663  0.02654967  0.28168431] 1.0 False\n",
      "[-0.05091235 -0.36811702  0.03218336  0.58262125] 1.0 False\n",
      "[-0.05827469 -0.1734604   0.04383579  0.30024779] 1.0 False\n",
      "[-0.0617439  -0.36917886  0.04984074  0.60642706] 1.0 False\n",
      "[-0.06912748 -0.56496099  0.06196928  0.91438268] 1.0 False\n",
      "[-0.0804267  -0.7608639   0.08025694  1.22588031] 1.0 False\n",
      "[-0.09564398 -0.56686172  0.10477454  0.95938395] 1.0 False\n",
      "[-0.10698121 -0.37329242  0.12396222  0.70136964] 1.0 False\n",
      "[-0.11444706 -0.1800869   0.13798961  0.45013682] 1.0 False\n",
      "[-0.1180488  -0.37686318  0.14699235  0.78293589] 1.0 False\n",
      "[-0.12558606 -0.18403416  0.16265107  0.53987184] 1.0 False\n",
      "[-0.12926674  0.00847274  0.17344851  0.30253156] 1.0 False\n",
      "[-0.12909729 -0.18864214  0.17949914  0.64450602] 1.0 False\n",
      "[-0.13287013 -0.38575136  0.19238926  0.98790929] 1.0 False\n",
      "[-0.14058516 -0.19365278  0.21214744  0.76129186] 1.0 True\n",
      "Reward for this episode was: 21.0\n",
      "[ 0.01450323  0.21876671  0.03872053 -0.26259773] 1.0 False\n",
      "[ 0.01887856  0.41331518  0.03346857 -0.54282071] 1.0 False\n",
      "[ 0.02714487  0.60795117  0.02261216 -0.82477328] 1.0 False\n",
      "[ 0.03930389  0.41252735  0.00611669 -0.52506508] 1.0 False\n",
      "[ 0.04755444  0.6075627  -0.00438461 -0.81581433] 1.0 False\n",
      "[ 0.05970569  0.80274441 -0.0207009  -1.10987315] 1.0 False\n",
      "[ 0.07576058  0.60790048 -0.04289836 -0.82375551] 1.0 False\n",
      "[ 0.08791859  0.41339079 -0.05937347 -0.54486764] 1.0 False\n",
      "[ 0.09618641  0.60929458 -0.07027082 -0.85565108] 1.0 False\n",
      "[ 0.1083723   0.80530015 -0.08738384 -1.16957645] 1.0 False\n",
      "[ 0.1244783   1.00144316 -0.11077537 -1.48832654] 1.0 False\n",
      "[ 0.14450716  1.1977264  -0.1405419  -1.81344817] 1.0 False\n",
      "[ 0.16846169  1.39410611 -0.17681087 -2.14629677] 1.0 False\n",
      "[ 0.19634381  1.20111375 -0.2197368  -1.91303344] 1.0 True\n",
      "Reward for this episode was: 14.0\n",
      "[ 0.00781196 -0.16183698 -0.04739864  0.26205068] 1.0 False\n",
      "[ 0.00457522  0.03392839 -0.04215763 -0.04519756] 1.0 False\n",
      "[ 0.00525379 -0.16056448 -0.04306158  0.23389187] 1.0 False\n",
      "[ 0.0020425   0.03514544 -0.03838374 -0.07205707] 1.0 False\n",
      "[ 0.00274541 -0.1594058  -0.03982488  0.2082728 ] 1.0 False\n",
      "[-0.00044271  0.03626231 -0.03565943 -0.09670207] 1.0 False\n",
      "[  2.82535355e-04   2.31876718e-01  -3.75934696e-02  -4.00418797e-01] 1.0 False\n",
      "[ 0.00492007  0.03730764 -0.04560185 -0.11982126] 1.0 False\n",
      "[ 0.00566622  0.23305228 -0.04799827 -0.42653528] 1.0 False\n",
      "[ 0.01032727  0.42882004 -0.05652898 -0.73395481] 1.0 False\n",
      "[ 0.01890367  0.62467554 -0.07120807 -1.04387945] 1.0 False\n",
      "[ 0.03139718  0.82066704 -0.09208566 -1.35803915] 1.0 False\n",
      "[ 0.04781052  1.01681536 -0.11924644 -1.67804999] 1.0 False\n",
      "[ 0.06814683  1.21310124 -0.15280744 -2.00536336] 1.0 False\n",
      "[ 0.09240885  1.01986721 -0.19291471 -1.76364052] 1.0 False\n",
      "[ 0.1128062   0.82737971 -0.22818752 -1.53663114] 1.0 True\n",
      "Reward for this episode was: 16.0\n",
      "[-0.02710045  0.16597135 -0.00623404 -0.28263715] 1.0 False\n",
      "[-0.02378103  0.36118166 -0.01188679 -0.57727972] 1.0 False\n",
      "[-0.01655739  0.16622832 -0.02343238 -0.288365  ] 1.0 False\n",
      "[-0.01323283 -0.02855178 -0.02919968 -0.00316356] 1.0 False\n",
      "[-0.01380386 -0.22324306 -0.02926295  0.28016539] 1.0 False\n",
      "[-0.01826872 -0.41793562 -0.02365965  0.56347712] 1.0 False\n",
      "[-0.02662743 -0.22248981 -0.0123901   0.26343517] 1.0 False\n",
      "[-0.03107723 -0.02719322 -0.0071214  -0.03312983] 1.0 False\n",
      "[-0.0316211  -0.22221233 -0.007784    0.25729774] 1.0 False\n",
      "[-0.03606534 -0.41722229 -0.00263804  0.54751535] 1.0 False\n",
      "[-0.04440979 -0.61230708  0.00831227  0.83936593] 1.0 False\n",
      "[-0.05665593 -0.80754153  0.02509958  1.13465128] 1.0 False\n",
      "[-0.07280676 -0.61275685  0.04779261  0.84994478] 1.0 False\n",
      "[-0.0850619  -0.80849681  0.06479151  1.15726515] 1.0 False\n",
      "[-0.10123183 -1.00440068  0.08793681  1.46953975] 1.0 False\n",
      "[-0.12131985 -1.20048159  0.1173276   1.78834476] 1.0 False\n",
      "[-0.14532948 -1.00685578  0.1530945   1.53431804] 1.0 False\n",
      "[-0.16546659 -0.81387342  0.18378086  1.29306438] 1.0 False\n",
      "[-0.18174406 -0.6215002   0.20964215  1.06309189] 1.0 True\n",
      "Reward for this episode was: 19.0\n",
      "[ 0.03616402 -0.14549357 -0.03518389  0.30066403] 1.0 False\n",
      "[ 0.03325415  0.05011174 -0.02917061 -0.00290428] 1.0 False\n",
      "[ 0.03425639  0.24563963 -0.02922869 -0.30464628] 1.0 False\n",
      "[ 0.03916918  0.05094614 -0.03532162 -0.0213228 ] 1.0 False\n",
      "[ 0.0401881   0.24655637 -0.03574807 -0.32493752] 1.0 False\n",
      "[ 0.04511923  0.05196117 -0.04224682 -0.0437389 ] 1.0 False\n",
      "[ 0.04615845  0.24766266 -0.0431216  -0.34944609] 1.0 False\n",
      "[ 0.05111171  0.44337053 -0.05011052 -0.65540881] 1.0 False\n",
      "[ 0.05997912  0.24898073 -0.0632187  -0.37891646] 1.0 False\n",
      "[ 0.06495873  0.05481087 -0.07079703 -0.10681741] 1.0 False\n",
      "[ 0.06605495  0.25087219 -0.07293338 -0.42096962] 1.0 False\n",
      "[ 0.07107239  0.44694763 -0.08135277 -0.7357243 ] 1.0 False\n",
      "[ 0.08001135  0.25303804 -0.09606726 -0.46971323] 1.0 False\n",
      "[ 0.08507211  0.44937645 -0.10546152 -0.79106325] 1.0 False\n",
      "[ 0.09405964  0.25584842 -0.12128279 -0.5333323 ] 1.0 False\n",
      "[ 0.0991766   0.06262222 -0.13194943 -0.28119186] 1.0 False\n",
      "[ 0.10042905 -0.13039495 -0.13757327 -0.03286353] 1.0 False\n",
      "[ 0.09782115  0.06640423 -0.13823054 -0.36559226] 1.0 False\n",
      "[ 0.09914923  0.2631921  -0.14554238 -0.69846891] 1.0 False\n",
      "[ 0.10441308  0.46000007 -0.15951176 -1.03319826] 1.0 False\n",
      "[ 0.11361308  0.65684225 -0.18017573 -1.37141098] 1.0 False\n",
      "[ 0.12674992  0.85370123 -0.20760395 -1.71460491] 1.0 False\n",
      "[ 0.14382395  0.66147818 -0.24189605 -1.49305964] 1.0 True\n",
      "Reward for this episode was: 23.0\n",
      "[ 0.00442488  0.22835446 -0.0251612  -0.33852194] 1.0 False\n",
      "[ 0.00899197  0.03359941 -0.03193164 -0.05387845] 1.0 False\n",
      "[ 0.00966396 -0.16105048 -0.03300921  0.22856123] 1.0 False\n",
      "[ 0.00644295  0.03452726 -0.02843799 -0.07434851] 1.0 False\n",
      "[ 0.00713349 -0.16017571 -0.02992496  0.20922821] 1.0 False\n",
      "[ 0.00392998  0.03536107 -0.02574039 -0.09274226] 1.0 False\n",
      "[ 0.0046372  -0.15938267 -0.02759524  0.19170973] 1.0 False\n",
      "[ 0.00144955 -0.3540992  -0.02376104  0.47556137] 1.0 False\n",
      "[-0.00563244 -0.54887771 -0.01424982  0.76066157] 1.0 False\n",
      "[-0.01660999 -0.35356237  0.00096341  0.463529  ] 1.0 False\n",
      "[-0.02368124 -0.15845405  0.01023399  0.17114989] 1.0 False\n",
      "[-0.02685032  0.03651994  0.01365699 -0.11828703] 1.0 False\n",
      "[-0.02611992  0.23144358  0.01129125 -0.4066302 ] 1.0 False\n",
      "[-0.02149105  0.03616335  0.00315865 -0.11040897] 1.0 False\n",
      "[-0.02076778  0.2312399   0.00095047 -0.40209369] 1.0 False\n",
      "[-0.01614298  0.42634836 -0.00709141 -0.69447681] 1.0 False\n",
      "[-0.00761602  0.23132549 -0.02098094 -0.40403471] 1.0 False\n",
      "[-0.00298951  0.03650728 -0.02906164 -0.11803966] 1.0 False\n",
      "[-0.00225936  0.2320333  -0.03142243 -0.41974777] 1.0 False\n",
      "[ 0.00238131  0.03737036 -0.03981738 -0.13713417] 1.0 False\n",
      "[ 0.00312871  0.23303933 -0.04256007 -0.44210821] 1.0 False\n",
      "[ 0.0077895   0.03854466 -0.05140223 -0.16313928] 1.0 False\n",
      "[ 0.00856039  0.23436334 -0.05466502 -0.47158494] 1.0 False\n",
      "[ 0.01324766  0.0400544  -0.06409672 -0.19662041] 1.0 False\n",
      "[ 0.01404875  0.23603182 -0.06802912 -0.50881443] 1.0 False\n",
      "[ 0.01876938  0.04193096 -0.07820541 -0.23832173] 1.0 False\n",
      "[ 0.019608    0.23807799 -0.08297185 -0.55461196] 1.0 False\n",
      "[ 0.02436956  0.43426096 -0.09406409 -0.8722398 ] 1.0 False\n",
      "[ 0.03305478  0.63052758 -0.11150888 -1.19295233] 1.0 False\n",
      "[ 0.04566533  0.82690308 -0.13536793 -1.51840186] 1.0 False\n",
      "[ 0.0622034   1.02337739 -0.16573597 -1.85009396] 1.0 False\n",
      "[ 0.08267094  1.21989066 -0.20273785 -2.1893283 ] 1.0 False\n",
      "[ 0.10706876  1.02722722 -0.24652441 -1.9654495 ] 1.0 True\n",
      "Reward for this episode was: 33.0\n",
      "[ -8.31581251e-05   2.32773602e-01   3.26422123e-02  -2.50339298e-01] 1.0 False\n",
      "[ 0.00457231  0.03720108  0.02763543  0.05245831] 1.0 False\n",
      "[ 0.00531634  0.2319161   0.02868459 -0.23137891] 1.0 False\n",
      "[ 0.00995466  0.03639626  0.02405701  0.07021231] 1.0 False\n",
      "[ 0.01068258  0.2311652   0.02546126 -0.21478448] 1.0 False\n",
      "[ 0.01530589  0.03568867  0.02116557  0.08582008] 1.0 False\n",
      "[ 0.01601966  0.23050094  0.02288197 -0.20011065] 1.0 False\n",
      "[ 0.02062968  0.03505932  0.01887976  0.09970174] 1.0 False\n",
      "[ 0.02133087  0.22990567  0.02087379 -0.18696538] 1.0 False\n",
      "[ 0.02592898  0.03449139  0.01713449  0.11222864] 1.0 False\n",
      "[ 0.02661881 -0.16087184  0.01937906  0.41026776] 1.0 False\n",
      "[ 0.02340137 -0.35626309  0.02758441  0.70899669] 1.0 False\n",
      "[ 0.01627611 -0.16153386  0.04176435  0.42512275] 1.0 False\n",
      "[ 0.01304543 -0.35722175  0.0502668   0.73067378] 1.0 False\n",
      "[ 0.005901   -0.16282922  0.06488028  0.45422551] 1.0 False\n",
      "[ 0.00264441  0.03131819  0.07396479  0.18267853] 1.0 False\n",
      "[ 0.00327078  0.22530814  0.07761836 -0.08578496] 1.0 False\n",
      "[ 0.00777694  0.41923663  0.07590266 -0.353005  ] 1.0 False\n",
      "[ 0.01616167  0.22312204  0.06884256 -0.03738613] 1.0 False\n",
      "[ 0.02062411  0.4171927   0.06809484 -0.30757885] 1.0 False\n",
      "[ 0.02896797  0.22116987  0.06194326  0.00577837] 1.0 False\n",
      "[ 0.03339136  0.41535129  0.06205883 -0.26673546] 1.0 False\n",
      "[ 0.04169839  0.21940106  0.05672412  0.04485765] 1.0 False\n",
      "[ 0.04608641  0.41366567  0.05762127 -0.22940264] 1.0 False\n",
      "[ 0.05435972  0.6079189   0.05303322 -0.5033676 ] 1.0 False\n",
      "[ 0.0665181   0.41209116  0.04296587 -0.19445452] 1.0 False\n",
      "[ 0.07475993  0.60657301  0.03907678 -0.47327999] 1.0 False\n",
      "[ 0.08689139  0.80112192  0.02961118 -0.75339493] 1.0 False\n",
      "[ 0.10291382  0.99582336  0.01454328 -1.03661465] 1.0 False\n",
      "[ 0.12283029  1.190749   -0.00618901 -1.32469661] 1.0 False\n",
      "[ 0.14664527  1.38594857 -0.03268295 -1.61930991] 1.0 False\n",
      "[ 0.17436424  1.58144004 -0.06506914 -1.92199759] 1.0 False\n",
      "[ 0.20599304  1.77719764 -0.1035091  -2.23412942] 1.0 False\n",
      "[ 0.241537    1.97313727 -0.14819168 -2.55684314] 1.0 False\n",
      "[ 0.28099974  1.77947684 -0.19932855 -2.31294542] 1.0 False\n",
      "[ 0.31658928  1.97578567 -0.24558746 -2.65979352] 1.0 True\n",
      "Reward for this episode was: 36.0\n",
      "[-0.00647388 -0.19461712  0.04351699  0.34342587] 1.0 False\n",
      "[-0.01036623 -0.00014041  0.05038551  0.06477692] 1.0 False\n",
      "[-0.01036903 -0.19594719  0.05168104  0.37292143] 1.0 False\n",
      "[-0.01428798 -0.39176376  0.05913947  0.68144157] 1.0 False\n",
      "[-0.02212325 -0.58765503  0.0727683   0.99214166] 1.0 False\n",
      "[-0.03387635 -0.39357825  0.09261114  0.72317191] 1.0 False\n",
      "[-0.04174792 -0.19985094  0.10707458  0.461015  ] 1.0 False\n",
      "[-0.04574494 -0.39631045  0.11629488  0.78543638] 1.0 False\n",
      "[-0.05367115 -0.20296198  0.1320036   0.53148635] 1.0 False\n",
      "[-0.05773039 -0.00991966  0.14263333  0.28313848] 1.0 False\n",
      "[-0.05792878 -0.2067574   0.1482961   0.61718895] 1.0 False\n",
      "[-0.06206393 -0.01398422  0.16063988  0.37464234] 1.0 False\n",
      "[-0.06234361 -0.21097987  0.16813273  0.71335664] 1.0 False\n",
      "[-0.06656321 -0.40798117  0.18239986  1.05389016] 1.0 False\n",
      "[-0.07472283 -0.21568386  0.20347766  0.82355788] 1.0 False\n",
      "[-0.07903651 -0.41292105  0.21994882  1.17272056] 1.0 True\n",
      "Reward for this episode was: 16.0\n",
      "[-0.00755396  0.21646523  0.00779888 -0.30214828] 1.0 False\n",
      "[-0.00322466  0.41147517  0.00175591 -0.59236144] 1.0 False\n",
      "[ 0.00500485  0.60657249 -0.01009131 -0.88449074] 1.0 False\n",
      "[ 0.0171363   0.80183    -0.02778113 -1.18032888] 1.0 False\n",
      "[ 0.0331729   0.60707951 -0.05138771 -0.89648247] 1.0 False\n",
      "[ 0.04531449  0.80285907 -0.06931736 -1.20486548] 1.0 False\n",
      "[ 0.06137167  0.99880507 -0.09341467 -1.51844164] 1.0 False\n",
      "[ 0.08134777  1.19492426 -0.1237835  -1.8387618 ] 1.0 False\n",
      "[ 0.10524626  1.0013681  -0.16055874 -1.5869485 ] 1.0 False\n",
      "[ 0.12527362  0.80847736 -0.19229771 -1.34833551] 1.0 False\n",
      "[ 0.14144316  1.00542433 -0.21926442 -1.69449843] 1.0 True\n",
      "Reward for this episode was: 11.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "random_episodes = 0\n",
    "reward_sum = 0\n",
    "\n",
    "while random_episodes < 10:    \n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    print(observation, reward, done)\n",
    "    reward_sum += reward\n",
    "    if done:\n",
    "        random_episodes += 1\n",
    "        print(\"Reward for this episode was:\", reward_sum)\n",
    "        reward_sum = 0\n",
    "        env.reset()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, reward, done, _ = env.step(a)\n",
    "if done:\n",
    "    Qs[0, a] = -100\n",
    "else:\n",
    "    x1 = np.reshape(sq, [1, input_size])\n",
    "    # Obtain the Q' values by feeding the new state throught our network\n",
    "    Qs1 = sess.run(Qpred, feed_dict={X: x1})\n",
    "    Qs[0, a] = reward + dis * np.max(Qs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: Network and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable W1 already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-1-bda5e61473b1>\", line 15, in <module>\n    initializer=tf.contrib.layers.xavier_initializer())\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-67bc1dbafc80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# First layer of weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m W1 = tf.get_variable('W1', shape=[input_size, output_size],\n\u001b[0;32m---> 15\u001b[0;31m                     initializer=tf.contrib.layers.xavier_initializer())\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    662\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 664\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable W1 already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-1-bda5e61473b1>\", line 15, in <module>\n    initializer=tf.contrib.layers.xavier_initializer())\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "# Constants defining our neural network\n",
    "learning_rate = 1e-1\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, input_size], name='input_x')\n",
    "\n",
    "# First layer of weights\n",
    "W1 = tf.get_variable('W1', shape=[input_size, output_size],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qpred = tf.matmul(X, W1)\n",
    "\n",
    "# We need to define th parts of the network needed for learning a policy\n",
    "Y = tf.placeholder(shape=[None, output_size], dtype=tf.float32)\n",
    "\n",
    "# Loss function\n",
    "loss = tf.reduce_sum(tf.square(Y - Qpred))\n",
    "# Learning\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Values for q learning\n",
    "num_episodes = 2000\n",
    "dis = 0.9\n",
    "rList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
